{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNanLEXjoLVIgo1wQBU2p7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayureshpawashe/spark/blob/main/Sparkbasic_day4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spark Day 4"
      ],
      "metadata": {
        "id": "ftXnZbc2Af_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tungsten Code"
      ],
      "metadata": {
        "id": "7DIxq3n9Alek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "oiA7yDZWDHkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"PySparkAPI\").getOrCreate()\n",
        "data = [(\"Mayuresh\", 25), (\"Onkar\", 30), (\"Rohit\", 35)]\n",
        "columns = [\"Name\", \"Age\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxcXv4LNAkGP",
        "outputId": "eef80f37-f6a8-4db1-e826-aa6dfcd09c46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+\n",
            "|    Name|Age|\n",
            "+--------+---+\n",
            "|Mayuresh| 25|\n",
            "|   Onkar| 30|\n",
            "|   Rohit| 35|\n",
            "+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame with a large dataset\n",
        "big_data = [(i, f\"User{i}\", i * 2) for i in range(1, 100000)]\n",
        "columns = [\"ID\", \"Name\", \"Value\"]\n",
        "df = spark.createDataFrame(big_data, columns)\n",
        "df.groupBy(\"Name\").sum(\"Value\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xZSp8n9Efjm",
        "outputId": "5bb994b9-021e-4782-f155-e19c5b70b51e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+\n",
            "|    Name|sum(Value)|\n",
            "+--------+----------+\n",
            "| User285|       570|\n",
            "| User509|      1018|\n",
            "| User958|      1916|\n",
            "|User1212|      2424|\n",
            "|User1292|      2584|\n",
            "|User1346|      2692|\n",
            "|User1690|      3380|\n",
            "|User2093|      4186|\n",
            "|User2757|      5514|\n",
            "|User2782|      5564|\n",
            "|User2977|      5954|\n",
            "|User3131|      6262|\n",
            "|User3176|      6352|\n",
            "|User3403|      6806|\n",
            "|User3819|      7638|\n",
            "|User3839|      7678|\n",
            "|User3991|      7982|\n",
            "|User4271|      8542|\n",
            "|User4494|      8988|\n",
            "|User4535|      9070|\n",
            "+--------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##After Tungsten (With Optimization)"
      ],
      "metadata": {
        "id": "KHfn9mFcEww9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Name\").sum(\"Value\").explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BonSYiL8EsMP",
        "outputId": "3293289b-874a-4ebd-e522-7b56ac0e95cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[Name#27], functions=[sum(Value#28L)])\n",
            "   +- Exchange hashpartitioning(Name#27, 200), ENSURE_REQUIREMENTS, [plan_id=85]\n",
            "      +- HashAggregate(keys=[Name#27], functions=[partial_sum(Value#28L)])\n",
            "         +- Project [Name#27, Value#28L]\n",
            "            +- Scan ExistingRDD[ID#26L,Name#27,Value#28L]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tungsten optimizes Spark jobs by reducing execution overhead and improving memory usage"
      ],
      "metadata": {
        "id": "4MWm1RLvE7Xk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Catalyst Optimizer Code"
      ],
      "metadata": {
        "id": "b9W7vCaPFNPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "data = [(\"Alice\", 25, \"Engineer\"), (\"Bob\", 30, \"Doctor\"), (\"Charlie\", 35, \"Teacher\")]\n",
        "columns = [\"Name\", \"Age\", \"Profession\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "filtered_df = df.filter(col(\"Age\") > 28)\n",
        "# Show optimized execution plan\n",
        "filtered_df.explain()\n",
        "###Catalyst Optimizer ensures filtering happens before scanning, making it faster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7leAK-q9FQPG",
        "outputId": "0d396611-f65c-4aa8-eca7-153f15af062f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) Filter (isnotnull(Age#67L) AND (Age#67L > 28))\n",
            "+- *(1) Scan ExistingRDD[Name#66,Age#67L,Profession#68]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup Spark Session"
      ],
      "metadata": {
        "id": "MTXCQ7nCRWmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum, count, avg\n",
        "import time\n",
        "spark = SparkSession.builder.appName(\"Tungsten_Catalyst_Example\").getOrCreate()\n",
        "data = [(i, f\"User{i % 1000}\", i * 1.5, (i % 5) + 1) for i in range(1, 1000000)]\n",
        "columns = [\"ID\", \"Username\", \"Amount\", \"Category\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show(15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r-6Fzz4JSbO",
        "outputId": "28f241af-7803-4279-8f1a-bad71d503881"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+------+--------+\n",
            "| ID|Username|Amount|Category|\n",
            "+---+--------+------+--------+\n",
            "|  1|   User1|   1.5|       2|\n",
            "|  2|   User2|   3.0|       3|\n",
            "|  3|   User3|   4.5|       4|\n",
            "|  4|   User4|   6.0|       5|\n",
            "|  5|   User5|   7.5|       1|\n",
            "|  6|   User6|   9.0|       2|\n",
            "|  7|   User7|  10.5|       3|\n",
            "|  8|   User8|  12.0|       4|\n",
            "|  9|   User9|  13.5|       5|\n",
            "| 10|  User10|  15.0|       1|\n",
            "| 11|  User11|  16.5|       2|\n",
            "| 12|  User12|  18.0|       3|\n",
            "| 13|  User13|  19.5|       4|\n",
            "| 14|  User14|  21.0|       5|\n",
            "| 15|  User15|  22.5|       1|\n",
            "+---+--------+------+--------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Catalyst Optimizer in Action"
      ],
      "metadata": {
        "id": "1V8OXCfCR0NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "optimized_df = (\n",
        "    df.filter(col(\"Amount\") > 1000)\n",
        "      .groupBy(\"Category\")\n",
        "      .agg(\n",
        "          sum(\"Amount\").alias(\"Total_Amount\"),\n",
        "          avg(\"Amount\").alias(\"Average_Amount\"),\n",
        "          count(\"ID\").alias(\"Transaction_Count\")\n",
        "      )\n",
        "      .orderBy(col(\"Total_Amount\").desc())\n",
        ")\n",
        "optimized_df.explain(mode=\"formatted\")\n",
        "optimized_df.show()\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Execution Time: {round(end_time - start_time, 2)} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0bBTiqeR4yg",
        "outputId": "a490f8af-e2ea-4328-edc5-87b11ce397cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan (9)\n",
            "+- Sort (8)\n",
            "   +- Exchange (7)\n",
            "      +- HashAggregate (6)\n",
            "         +- Exchange (5)\n",
            "            +- HashAggregate (4)\n",
            "               +- Project (3)\n",
            "                  +- Filter (2)\n",
            "                     +- Scan ExistingRDD (1)\n",
            "\n",
            "\n",
            "(1) Scan ExistingRDD\n",
            "Output [4]: [ID#25L, Username#26, Amount#27, Category#28L]\n",
            "Arguments: [ID#25L, Username#26, Amount#27, Category#28L], MapPartitionsRDD[11] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n",
            "\n",
            "(2) Filter\n",
            "Input [4]: [ID#25L, Username#26, Amount#27, Category#28L]\n",
            "Condition : (isnotnull(Amount#27) AND (Amount#27 > 1000.0))\n",
            "\n",
            "(3) Project\n",
            "Output [3]: [ID#25L, Amount#27, Category#28L]\n",
            "Input [4]: [ID#25L, Username#26, Amount#27, Category#28L]\n",
            "\n",
            "(4) HashAggregate\n",
            "Input [3]: [ID#25L, Amount#27, Category#28L]\n",
            "Keys [1]: [Category#28L]\n",
            "Functions [3]: [partial_sum(Amount#27), partial_avg(Amount#27), partial_count(ID#25L)]\n",
            "Aggregate Attributes [4]: [sum#64, sum#65, count#66L, count#67L]\n",
            "Results [5]: [Category#28L, sum#68, sum#69, count#70L, count#71L]\n",
            "\n",
            "(5) Exchange\n",
            "Input [5]: [Category#28L, sum#68, sum#69, count#70L, count#71L]\n",
            "Arguments: hashpartitioning(Category#28L, 200), ENSURE_REQUIREMENTS, [plan_id=47]\n",
            "\n",
            "(6) HashAggregate\n",
            "Input [5]: [Category#28L, sum#68, sum#69, count#70L, count#71L]\n",
            "Keys [1]: [Category#28L]\n",
            "Functions [3]: [sum(Amount#27), avg(Amount#27), count(ID#25L)]\n",
            "Aggregate Attributes [3]: [sum(Amount#27)#54, avg(Amount#27)#56, count(ID#25L)#58L]\n",
            "Results [4]: [Category#28L, sum(Amount#27)#54 AS Total_Amount#55, avg(Amount#27)#56 AS Average_Amount#57, count(ID#25L)#58L AS Transaction_Count#59L]\n",
            "\n",
            "(7) Exchange\n",
            "Input [4]: [Category#28L, Total_Amount#55, Average_Amount#57, Transaction_Count#59L]\n",
            "Arguments: rangepartitioning(Total_Amount#55 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=50]\n",
            "\n",
            "(8) Sort\n",
            "Input [4]: [Category#28L, Total_Amount#55, Average_Amount#57, Transaction_Count#59L]\n",
            "Arguments: [Total_Amount#55 DESC NULLS LAST], true, 0\n",
            "\n",
            "(9) AdaptiveSparkPlan\n",
            "Output [4]: [Category#28L, Total_Amount#55, Average_Amount#57, Transaction_Count#59L]\n",
            "Arguments: isFinalPlan=false\n",
            "\n",
            "\n",
            "+--------+-----------------+--------------+-----------------+\n",
            "|Category|     Total_Amount|Average_Amount|Transaction_Count|\n",
            "+--------+-----------------+--------------+-----------------+\n",
            "|       5| 1.50000383367E11|      750501.0|           199867|\n",
            "|       4|1.500000835665E11|      750499.5|           199867|\n",
            "|       3| 1.49999783766E11|      750498.0|           199867|\n",
            "|       2|1.499994829665E11|     750500.25|           199866|\n",
            "|       1|1.499991831675E11|     750498.75|           199866|\n",
            "+--------+-----------------+--------------+-----------------+\n",
            "\n",
            "Execution Time: 9.3 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Project Tungsten in Action"
      ],
      "metadata": {
        "id": "x4edogyISIOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_df.explain(mode=\"cost\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8-hDEOGSJPX",
        "outputId": "a0160437-17f4-4139-a37d-ddf3698dd99c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Optimized Logical Plan ==\n",
            "Sort [Total_Amount#55 DESC NULLS LAST], true, Statistics(sizeInBytes=6.2 EiB)\n",
            "+- Aggregate [Category#28L], [Category#28L, sum(Amount#27) AS Total_Amount#55, avg(Amount#27) AS Average_Amount#57, count(ID#25L) AS Transaction_Count#59L], Statistics(sizeInBytes=6.2 EiB)\n",
            "   +- Project [ID#25L, Amount#27, Category#28L], Statistics(sizeInBytes=4.9 EiB)\n",
            "      +- Filter (isnotnull(Amount#27) AND (Amount#27 > 1000.0)), Statistics(sizeInBytes=8.0 EiB)\n",
            "         +- LogicalRDD [ID#25L, Username#26, Amount#27, Category#28L], false, Statistics(sizeInBytes=8.0 EiB)\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [Total_Amount#55 DESC NULLS LAST], true, 0\n",
            "   +- Exchange rangepartitioning(Total_Amount#55 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=50]\n",
            "      +- HashAggregate(keys=[Category#28L], functions=[sum(Amount#27), avg(Amount#27), count(ID#25L)], output=[Category#28L, Total_Amount#55, Average_Amount#57, Transaction_Count#59L])\n",
            "         +- Exchange hashpartitioning(Category#28L, 200), ENSURE_REQUIREMENTS, [plan_id=47]\n",
            "            +- HashAggregate(keys=[Category#28L], functions=[partial_sum(Amount#27), partial_avg(Amount#27), partial_count(ID#25L)], output=[Category#28L, sum#68, sum#69, count#70L, count#71L])\n",
            "               +- Project [ID#25L, Amount#27, Category#28L]\n",
            "                  +- Filter (isnotnull(Amount#27) AND (Amount#27 > 1000.0))\n",
            "                     +- Scan ExistingRDD[ID#25L,Username#26,Amount#27,Category#28L]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}